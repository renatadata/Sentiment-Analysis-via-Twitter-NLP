{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac1a3d54",
   "metadata": {},
   "source": [
    "# Federal Reserve Sentiment Analysis via Twitter's Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebefd6",
   "metadata": {},
   "source": [
    "### A relatively newer trend in text analysis goes beyond topic detection and attempts to identify the emotion behind a text. This is called sentiment analysis, or also opinion mining and emotion AI.\n",
    "\n",
    "Sentiment Analysis is the process of 'computationally' determining whether a text is positive, negative or neutral. It is also known as opinion mining, deriving the opinion or attitude of a speaker.\n",
    "\n",
    "We will use Python and a Twitter Developer account to get the data regarding the latest Federal Reserve posts.\n",
    "\n",
    "The Federal Reserve System (the FED, also translated as the Federal Reserve System) is an American institution responsible for supervising the banking system and defining the monetary policy applied in the country.\n",
    "\n",
    "Their decisions influence not only the US economy but the entire world.\n",
    "\n",
    "We start by importing the Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbd78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "from googletrans import Translator\n",
    "from unidecode import unidecode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a447d94a",
   "metadata": {},
   "source": [
    "#### Authentication:\n",
    "To fetch tweets through the Twitter API, you need to register an application through your twitter account. Follow these steps for the same:\n",
    "\n",
    "Open this link and click the button: ‘Create New App’\n",
    "Fill in the application data. You can leave the callback url field empty.\n",
    "Once the app is created, you will be redirected to the app page.\n",
    "Open the ‘Access Keys and Tokens’ tab.\n",
    "Copy 'Consumer Key', 'Consumer Secret', 'Access Token' and 'Access Token Secret'.\n",
    "Just below you will include the copied keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188f182",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumerKey = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "consumerSecret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "accessToken = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "accessTokenSecret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbda31",
   "metadata": {},
   "source": [
    "#### We will then create the authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c865d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumerKey,consumerSecret)\n",
    "#\"Directing\" the access token\n",
    "auth.set_access_token(accessToken, accessTokenSecret) \n",
    "#Creating API object using our credentials\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113636c",
   "metadata": {},
   "source": [
    "#### Here we will define the account to be analyzed (federalreserve) and the language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_id = 'federalreserve'\n",
    "language = 'en'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e8e47",
   "metadata": {},
   "source": [
    "#### Now we will scrape the last 10 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbc182",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = api.user_timeline(screen_name=name_id,\n",
    "                          count = 10,\n",
    "                          lang =language,\n",
    "                          tweet_mode=\"extended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d843f3",
   "metadata": {},
   "source": [
    "#### We are going to use List Comprehension which allows you to create and process lists cleanly and easily to insert into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b168fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets=pd.DataFrame([tweet.full_text for tweet in posts], columns=['Tweets'])\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647e6ba",
   "metadata": {},
   "source": [
    "#### Defining the cleaning function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d34e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpando_chars(text):\n",
    "    text = re.sub('@[A-Za-z0–9]+', '', text) #removing @\n",
    "    text = re.sub('#', '', text) #removing #\n",
    "    text = re.sub('RT[\\s]+', '', text) #removing RT\n",
    "    text = re.sub('https?:\\/\\/\\S+', '', text) #removing hyperlink\n",
    "    text = re.sub('&amp','', text) #removing HTML markup from start\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc83e0f",
   "metadata": {},
   "source": [
    "#### Running the cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ec221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets['Tweets'] = df_tweets['Tweets'].apply(limpando_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d169a9c",
   "metadata": {},
   "source": [
    "#### Defining Subjectivity and Polarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that analyzes and obtains subjectivity\n",
    "def capture_subjetividade_pt(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "# Function that analyzes and obtains polarity\n",
    "def capture_polaridade_pt(text):\n",
    "    return  TextBlob(text).sentiment.polarity\n",
    "def translate_text(text):\n",
    "    return Translator().translate(unidecode(text)).text\n",
    "#translating\n",
    "if language!= 'en':\n",
    "    df_tweets['Tweets'] = df_tweets['Tweets'].apply(translate_text)\n",
    "else:\n",
    "    pass\n",
    "# Create two columns of subjectivity and polarity\n",
    "df_tweets['Subjetividade'] = df_tweets['Tweets'].apply(capture_polaridade_pt)\n",
    "df_tweets['Polaridade'] = df_tweets['Tweets'].apply(capture_subjetividade_pt)\n",
    "# Shows a new dataframe with the subjectivity and polarity columns\n",
    "df_tweets.tail()\n",
    "\n",
    "##Code based on the original by the author Germano Yoneda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d41c9",
   "metadata": {},
   "source": [
    "#### Creating the Analysis generation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_analise(score):\n",
    "    if score < 0:\n",
    "        return 'Negativo'\n",
    "    elif score == 0:\n",
    "        return 'Neutro'\n",
    "    else:\n",
    "        return 'Positivo'\n",
    "df_tweets['Analise'] = df_tweets['Polaridade'].apply(gerar_analise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d806e41",
   "metadata": {},
   "source": [
    "#### We then store the result in a Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780af334",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(df_tweets['Analise'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e17caf",
   "metadata": {},
   "source": [
    "#### Visualizing the result through a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.barplot(x=resultado['Analise'], y=df.index, data=df_tweets)\n",
    "ax.set_xlabel('Number of tweets')\n",
    "ax.set_ylabel('Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d049d",
   "metadata": {},
   "source": [
    "#### This approach is very interesting especially if applied to real-time Dashboards and combined with other analyses. This is just a study of the tool's possibilities.\n",
    "Always remembering: This is just a preliminary high risk trading strategy study for information purposes only. In any strategy, the following must always be considered: Risk Management, Operating Costs, Risk Tolerance Profile, etc. This article is by no means an investment recommendation.\n",
    "\n",
    "— — — — — — — — — — — — — — — — — — — — — — — — —\n",
    "\n",
    "Sources:\n",
    "\n",
    "infoq.com\n",
    "\n",
    "geeksforgeeks.org\n",
    "\n",
    "Germano Yoneda\n",
    "\n",
    "maisretorno.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
